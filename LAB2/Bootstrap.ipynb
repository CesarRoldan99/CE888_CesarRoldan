{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bootstrap.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CesarRoldan99/CEE88_Cesar/blob/main/LAB2/Bootstrap.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCi_99yMYIb1"
      },
      "source": [
        "In this notebook you'll create your own bootstrap function following the bootstrap algorithm (check the lecture notes!)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LY5zujI2YC37",
        "pycharm": {
          "name": "#%%# Imports\n"
        }
      },
      "source": [
        "import matplotlib\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import math "
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eqkwj4SMY38t"
      },
      "source": [
        "# Load the data\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/albanda/CE888/master/lab2%20-%20bootstrap/customers.csv')\n",
        "data = df.values.T[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gxvc_bScYC4H",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "# Checking the notes from the lecture, create here your own bootstrap function:\n",
        "# 1. Sample from the input array x to create an array of samples of shape (n_bootstraps, sample_size)\n",
        "# Hint: Check the function random.choice() on Numpy\n",
        "# 2. Calculate and save the mean of the array (this is \"data_mean\" that is returned by the function)\n",
        "# 3. Calculate the mean from each bootstrap (i.e., row) and store it.\n",
        "# (This should be an array of n_bootstraps values)\n",
        "# 4. Calculate the lower and upper bounds for a 95% CI (hint: check the percentile function on Numpy)\n",
        "# 5. Return data_mean, and the lower and upper bounds of your interval\n",
        "\n",
        "def bootstrap_mean(x, sample_size, n_bootstraps):\n",
        "    a=np.empty((n_bootstraps,sample_size))  # Empty matrix n_boots. rows, sample_size columns\n",
        "    b=np.empty((1,n_bootstraps))        # Empty array 1 row, n_boots. columns\n",
        "  \n",
        "    for i in range(n_bootstraps):\n",
        "        a[i]=np.random.choice(x,sample_size)    # Filling array a with bootstraps.\n",
        "        b[0,i]=np.mean(a[i])   # Forming array with means.\n",
        "  \n",
        "    b.sort()              # Sorting means within array. \n",
        "    data_mean=np.mean(data_mean)      # Mean of array data_mean \n",
        "    lower=np.percentile(b,2.5)        # Lower boundary.\n",
        "    upper=np.percentile(b,97.5)       # Upper boundary.\n",
        "\n",
        "    return data_mean, lower, upper\n"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AN7sEOcMYC4P",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "# Call your bootstrap function and plot the results\n",
        "\n",
        "boots = []\n",
        "for i in range(100, 50000, 1000):\n",
        "    boot = bootstrap_mean(data, data.shape[0], i)\n",
        "    boots.append([i, boot[0], \"mean\"])\n",
        "    boots.append([i, boot[1], \"lower\"])\n",
        "    boots.append([i, boot[2], \"upper\"])\n",
        "\n",
        "\n",
        "df_boot = pd.DataFrame(boots, columns=['Bootstrap Iterations', 'Mean', \"Value\"])\n",
        "\n",
        "sns_plot = sns.lmplot(df_boot.columns[0], df_boot.columns[1], data=df_boot, fit_reg=False, hue=\"Value\")\n",
        "\n",
        "sns_plot.axes[0, 0].set_ylim(0)\n",
        "sns_plot.axes[0, 0].set_xlim(0, 100000)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjtP4e2_YC4V"
      },
      "source": [
        "\n",
        "Now, modify the bootstrap function you created above so that you can pass your desired confidence interval as a parameter.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3K9j0FuGYhHs"
      },
      "source": [
        "def bootstrap_mean_ci(sample, sample_size, n_bootstraps, ci): # ci in percentage\n",
        "    a=np.empty((n_bootstraps, sample_size))   # Empty matrix n_boots. rows, sample_size columns\n",
        "    b=np.empty((1, n_bootstraps)) # Empty array 1 row, n_boots. columns\n",
        "    for i in range (n_bootstraps):\n",
        "        a[i]=np.random.choice(sample, sample_size) # Filling array a with bootstraps.\n",
        "        b[0,i]=np.mean(a[i])   # Forming array with means.\n",
        "    \n",
        "    b.sort()  # Sorting means within array.\n",
        "    NumCI=(100-ci)/2 \n",
        "\n",
        "    lower=np.percentile(b,NumCI) # Lower boundary.\n",
        "    upper=np.percentile(b,(100-NumCI)) # Upper boundary.\n",
        "\n",
        "    data_mean=np.mean(b) # Mean of array data_mean\n",
        "  \n",
        "    return data_mean,lower,upper"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDnjq08GYl-C"
      },
      "source": [
        "boots = []\n",
        "for i in range(100, 50000, 1000):\n",
        "    boot = bootstrap_mean_ci(data, data.shape[0], i, 80)\n",
        "    boots.append([i, boot[0], \"mean\"])\n",
        "    boots.append([i, boot[1], \"lower\"])\n",
        "    boots.append([i, boot[2], \"upper\"])\n",
        "\n",
        "df_boot = pd.DataFrame(boots, columns=['Boostrap Iterations', 'Mean', \"Value\"])\n",
        "sns_plot = sns.lmplot(df_boot.columns[0], df_boot.columns[1], data=df_boot, fit_reg=False, hue=\"Value\")\n",
        "\n",
        "sns_plot.axes[0, 0].set_ylim(0,)\n",
        "sns_plot.axes[0, 0].set_xlim(0, 100000)\n",
        "\n",
        "#sns_plot.savefig(\"bootstrap_confidence_80.pdf\", bbox_inches='tight')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjNgXW6wdd7r"
      },
      "source": [
        "# Vehicles dataset\n",
        "\n",
        "Now let's work on a different dataset, which is stored in the vehicles.csv file.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avWv4ipFdpka"
      },
      "source": [
        "# Load and visualise the vehicles dataset\n",
        "# To load the dataset: https://neptune.ai/blog/google-colab-dealing-with-files (check section \"Load individual files directly from GitHub\")\n",
        "\n",
        "\n",
        "# Note that the current and new fleets are in different columns and have different lengths, so bear this in mind when you're plotting.\n",
        "# You can create separate scatterplots for the two fleets, as you would with the histograms, \n",
        "# or plot them both in one plot (but not one against the other).\n",
        "# Note: you can add more cells as needed to organise your code and your plots\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCR1EQnuiz0k"
      },
      "source": [
        "# Reading data.\r\n",
        "dfVehicles = pd.read_csv('https://raw.githubusercontent.com/albanda/CE888/master/lab2%20-%20bootstrap/vehicles.csv')\r\n",
        "dfVehicles.head()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SOFyrr1jbrJ"
      },
      "source": [
        "# Plotting the data\r\n",
        "sns.scatterplot(data=dfVehicles)\r\n",
        "sns.set(style=\"darkgrid\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5d0tXDpIEj8"
      },
      "source": [
        "## Compare the two fleets\r\n",
        "\r\n",
        "The business analysts come up a comparison algorithm that requires the upper and lower bounds for the mean in order to say which fleet is better.\r\n",
        "1. Calculate the mean of both samples.\r\n",
        "2. Using the bootstrap function that you created:\r\n",
        "    - Construct the 95% CI of the mean of the current fleet.\r\n",
        "    - Construct the 95% CI of the mean of the new fleet.\r\n",
        "    - Are they comparable? (i.e., is one better than the other?) -- you can do this with a permutation test (check the lecture notes!)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "po4mp6zRHC0m"
      },
      "source": [
        "# 1. Mean of both samples\n",
        "print(\"The mean of the Current Fleet: \", np.mean(dfVehicles[\"Current fleet\"]))      # Current fleet's mean\n",
        "print(\"The mean of the New Fleet: \", np.mean(dfVehicles[\"New Fleet\"]))      # New fleet's mean"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zqTuNR_nFIt"
      },
      "source": [
        "# 2. Bootstrapping\r\n",
        "\r\n",
        "NF=[]\r\n",
        "CF=[]\r\n",
        "for i in dfVehicles[\"New Fleet\"]:       # Eliminating NaNs, Not a number. As the samples have different lengh. New fleet is shorter.\r\n",
        "    if math.isnan(i)== False:           # Checking if the value i is a NaN value, if not:\r\n",
        "        NF.append(i)                    # Append value i to list NF\r\n",
        "\r\n",
        "for j in dfVehicles[\"Current fleet\"]:\r\n",
        "    CF.append(j)\r\n",
        "\r\n",
        "CurrentFleet_mean=bootstrap_mean_ci(CF, len(CF), 10000, 95 )  # Bootsrapping Current Fleet, n=1000, ci=95\r\n",
        "NewFleet_mean=bootstrap_mean_ci(NF, len(NF), 10000, 95 )        # Bootsrapping New Fleet, n=1000, ci=95\r\n",
        "\r\n",
        "print(\"The mean of the Current Fleet: \", CurrentFleet_mean[0])      # Current fleet's mean\r\n",
        "print(\"The mean of the Current Fleet: \", NewFleet_mean[0])      # Current fleet's mean"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkxvDZG4HC0n"
      },
      "source": [
        "# Create your own function for a permutation test here (you will need it for the lab quiz!):\n",
        "def permut_test(sample1, sample2, n_permutations):\n",
        "    \"\"\"\n",
        "    sample1: 1D array\n",
        "    sample2: 1D array (note that the size of the two arrays can be different)\n",
        "    n_permutations: number of permutations to calculate the p-value\n",
        "    \"\"\"\n",
        "  \n",
        "    Xold = np.mean(sample1)       # Mean of sample1\n",
        "    Xnew = np.mean(sample2)       # Mean of sample2\n",
        "    tobs = Xnew-Xold              # t obs\n",
        "\n",
        "    count = 0                     # Counter for tperm>tobs\n",
        "    concat = np.concatenate((sample1,sample2))    # Concatenate sample1 and sample2\n",
        "\n",
        "    for i in range(n_permutations):                 # Run n_perm. times\n",
        "        perm = np.random.permutation(concat)          # Permutation of concat\n",
        "        Pold = perm[: int(len(perm)/2)]               # Resampling of old \n",
        "        Pnew = perm[int(len(perm)/2) :]               # Resampling of new\n",
        "        tperm = np.mean(Pnew) - np.mean(Pold)         # Tperm from means of old and new\n",
        "        if (tperm > tobs):                            # If tperm>tobs\n",
        "            count += 1                                # Increment counter\n",
        "\n",
        "    pvalue = count / n_permutations     # P value formula\n",
        "    return pvalue\n"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6L4kZgp3o7g"
      },
      "source": [
        "permut_test(CF, NF, 30000) # 100 permutations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTn_xFylUfp7"
      },
      "source": [
        "QUIZ LAB "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f52HWSWWZZWP"
      },
      "source": [
        "bootstrap_mean_ci(CF, len(CF), 10000, 92)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMDvpbQ9d5SJ"
      },
      "source": [
        "bootstrap_mean_ci(NF, len(NF), 10000, 95)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIN9pB3MRMPV"
      },
      "source": [
        "def bootstrap_std_ci(sample, sample_size, n_bootstraps, ci): # ci in percentage\r\n",
        "    a=np.empty((n_bootstraps, sample_size))   # Empty matrix n_boots. rows, sample_size columns\r\n",
        "    b=np.empty((1, n_bootstraps)) # Empty array 1 row, n_boots. columns\r\n",
        "    for i in range (n_bootstraps):\r\n",
        "        a[i]=np.random.choice(sample, sample_size) # Filling array a with bootstraps.\r\n",
        "        b[0,i]=np.std(a[i])   # Forming array with means.\r\n",
        "    \r\n",
        "    b.sort()  # Sorting means within array.\r\n",
        "    NumCI=(100-ci)/2 \r\n",
        "\r\n",
        "    data_std=np.std(b) # Mean of array data_mean\r\n",
        "\r\n",
        "    lower=np.percentile(b,NumCI) # Lower boundary.\r\n",
        "    upper=np.percentile(b,(100-NumCI)) # Upper boundary.    \r\n",
        "\r\n",
        "    return data_std,lower,upper\r\n",
        "\r\n",
        "bootstrap_std_ci(NF, len(NF), 10000, 73)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBFmXeavfZ4I"
      },
      "source": [
        "# Load the data\r\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/albanda/CE888/master/lab2%20-%20bootstrap/customers.csv')\r\n",
        "data = df.values.T[1]\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3oqD1sZkFuV"
      },
      "source": [
        "bootstrap_mean_ci(data, len(data), 10000, 95)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyRpYQDykksy",
        "outputId": "b6cb4b0d-cca1-41f6-f4f5-30b894a24150"
      },
      "source": [
        "bootstrap_std_ci(CF, len(CF), 10000, 95)"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.28945669816443675, 5.81016217919329, 6.94813774467977)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXLZLPIEf_6Z"
      },
      "source": [
        "permut_test(CF, NF, 30000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEeCRPJFUZzW"
      },
      "source": [
        "# The variables below represent the percentages of democratic votes in Pennsylvania and Ohio (one value for each state).\r\n",
        "dem_share_PA = [60.08, 40.64, 36.07, 41.21, 31.04, 43.78, 44.08, 46.85, 44.71, 46.15, 63.10, 52.20, 43.18, 40.24, 39.92, 47.87, 37.77, 40.11, 49.85, 48.61, 38.62, 54.25, 34.84, 47.75, 43.82, 55.97, 58.23, 42.97, 42.38, 36.11, 37.53, 42.65, 50.96, 47.43, 56.24, 45.60, 46.39, 35.22, 48.56, 32.97, 57.88, 36.05, 37.72, 50.36, 32.12, 41.55, 54.66, 57.81, 54.58, 32.88, 54.37, 40.45, 47.61, 60.49, 43.11, 27.32, 44.03, 33.56, 37.26, 54.64, 43.12, 25.34, 49.79, 83.56, 40.09, 60.81, 49.81]\r\n",
        "dem_share_OH = [56.94, 50.46, 65.99, 45.88, 42.23, 45.26, 57.01, 53.61, 59.10, 61.48, 43.43, 44.69, 54.59, 48.36, 45.89, 48.62, 43.92, 38.23, 28.79, 63.57, 38.07, 40.18, 43.05, 41.56, 42.49, 36.06, 52.76, 46.07, 39.43, 39.26, 47.47, 27.92, 38.01, 45.45, 29.07, 28.94, 51.28, 50.10, 39.84, 36.43, 35.71, 31.47, 47.01, 40.10, 48.76, 31.56, 39.86, 45.31, 35.47, 51.38, 46.33, 48.73, 41.77, 41.32, 48.46, 53.14, 34.01, 54.74, 40.67, 38.96, 46.29, 38.25, 6.80, 31.75, 46.33, 44.90, 33.57, 38.10, 39.67, 40.47, 49.44, 37.62, 36.71, 46.73, 42.20, 53.16, 52.40, 58.36, 68.02, 38.53, 34.58, 69.64, 60.50, 53.53, 36.54, 49.58, 41.97, 38.11]"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwkDXoOSVOZZ",
        "outputId": "57930bb6-a9c8-4af5-8bdd-e7fe2e6c77fe"
      },
      "source": [
        "print(len(dem_share_PA))\r\n",
        "print(len(dem_share_OH))"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "67\n",
            "88\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtGFuQUaVxB8",
        "outputId": "460d29de-03b8-48c5-aa5f-9f6a590b1ae0"
      },
      "source": [
        "print(bootstrap_mean_ci(dem_share_OH, len(dem_share_OH), 20000, 95))\r\n",
        "print(bootstrap_mean_ci(dem_share_PA, len(dem_share_PA), 20000, 95))"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(44.325475454545455, 42.26646875, 46.382392045454544)\n",
            "(45.4876860522388, 43.22619776119404, 47.86806716417911)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQ-qXzXnWXai",
        "outputId": "81dbfd42-0008-4de6-c79a-1dcf068414da"
      },
      "source": [
        "permut_test(dem_share_OH, dem_share_PA, 10000) # 100 permutations"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2373"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    }
  ]
}