{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "VGG_Model.ipynb",
      "provenance": [],
      "mount_file_id": "1IEniwkOdTPCqpyyj7zLG2jJuqqyhC0x3",
      "authorship_tag": "ABX9TyPM2rh6NN9iFqFF3F+dfbHK",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CesarRoldan99/CE888_CesarRoldan/blob/main/Assignment2/VGG_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9xomXI5QyZ4"
      },
      "source": [
        "# Data Science and Decision Making - Second Assignment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3swJDR6uRQ-A"
      },
      "source": [
        "All the following cells correspond to the process of loading, manipulating, split the data, as well as, train, save and test the model. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ysvqx-h1RtPg"
      },
      "source": [
        "*Keep the Library secion intact, as they are important for the proper function of the entire code. The requirements are in a README.txt file in the repository.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y19W1IKaG-ex"
      },
      "source": [
        "# Libraries.\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras import Model, layers\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgPRRUHNSJVo"
      },
      "source": [
        "*Training and test sets of images were uploaded to Google's drive. Therefore, if you want to make experiments, both train and test images should be in drive. Upload the images, right-click over the folder, copy and paste the file's path.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16raQbt-PSB2"
      },
      "source": [
        "# Directories of data.\n",
        "d_training = \"/content/drive/MyDrive/FLAME_DATASET/Training_R_V2\"\n",
        "d_test = \"/content/drive/MyDrive/FLAME_DATASET/Test_R\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Sj5T3uFS4O8"
      },
      "source": [
        "*This section can be modified or left as it is. Validation-split, subset, label_mode, shuffle and seed are extremely important. Modify with care!*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyudOzbdPVkP"
      },
      "source": [
        "# Image loading into train, validation, and test.\n",
        "train = image_dataset_from_directory(d_training,\n",
        "                                     batch_size=32,\n",
        "                                     labels=\"inferred\",\n",
        "                                     shuffle=True,\n",
        "                                     seed=100,\n",
        "                                     validation_split=0.2,\n",
        "                                     subset=\"training\",\n",
        "                                     label_mode=\"binary\")\n",
        "\n",
        "validation = image_dataset_from_directory(d_training,\n",
        "                                          batch_size=32,\n",
        "                                          labels=\"inferred\",\n",
        "                                          shuffle=True,\n",
        "                                          seed=100,\n",
        "                                          validation_split=0.2,\n",
        "                                          subset=\"validation\",\n",
        "                                          label_mode=\"binary\")\n",
        "\n",
        "test = image_dataset_from_directory(d_test,\n",
        "                                    batch_size=32,\n",
        "                                    labels=\"inferred\",\n",
        "                                    shuffle=True,\n",
        "                                    label_mode=\"binary\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPZn6BL7TedU"
      },
      "source": [
        "*Augmentation section. This only apply to the images within the training set. The resizing layer NEEDS to be modified is other model is expected to be used. VGG19 has an input of 224 x 224 x 3. Rescaling layer is also important as the normalization of the data improves efficiency while fitting the model.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnZve2kWPY3t"
      },
      "source": [
        "# Preprocessing Sequence\n",
        "augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.experimental.preprocessing.Resizing(224, 224),\n",
        "        layers.experimental.preprocessing.RandomFlip(mode=\"horizontal_and_vertical\"),\n",
        "        layers.experimental.preprocessing.RandomRotation(0.1),\n",
        "        layers.experimental.preprocessing.Rescaling(1.0 / 255)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Augmentation of data\n",
        "train_gen = train.map(lambda x, y: (augmentation(x, training=True), y))\n",
        "train_gen = train_gen.prefetch(buffer_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vt_SGsleUi2h"
      },
      "source": [
        "*This section resizes and normalize the data for the validation and the test sets.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJf_eemaPcAG"
      },
      "source": [
        "# Data normalization\n",
        "norm = keras.Sequential(\n",
        "    [\n",
        "        layers.experimental.preprocessing.Resizing(224, 224),\n",
        "        layers.experimental.preprocessing.Rescaling(1.0 / 255)\n",
        "    ]\n",
        ")\n",
        "\n",
        "val_gen = validation.map(lambda x, y: (norm(x, training=True), y))\n",
        "val_gen = val_gen.prefetch(buffer_size=32)\n",
        "\n",
        "test_gen = test.map(lambda x, y: (norm(x, training=True), y))\n",
        "test_gen = test_gen.prefetch(buffer_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcaS2BiQU538"
      },
      "source": [
        "*Using Keras for loading the pre-trained VGG19 model. Important: then using Imagenet's weights, classes' number must be 1000. The fully connected layers have been modified for binary classification.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5dnvOjAPlY7"
      },
      "source": [
        "# Loading pretrained model\n",
        "base_model = keras.applications.VGG19(include_top=True,\n",
        "                                      weights=\"imagenet\",\n",
        "                                      classes=1000)\n",
        "\n",
        "# Feature extraction\n",
        "img_input = base_model.inputs\n",
        "\n",
        "x = base_model.get_layer(\"block5_pool\").output\n",
        "x = Flatten(name='flatten')(x)\n",
        "x = Dense(4096, activation='relu', name='fc1')(x)\n",
        "x = Dropout(0.1)(x)\n",
        "x = Dense(2048, activation=\"relu\", name=\"fc2\")(x)\n",
        "x = Dense(1, activation='sigmoid', name='out')(x)\n",
        "\n",
        "model = Model(img_input, x)\n",
        "\n",
        "for layer in model.layers[:-5]:\n",
        "    layer.trainable = False\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vwGOpMlWHtA"
      },
      "source": [
        "*Compilation of the model using rmsprop, binary crossentropy and accuracy as the main metric.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgwf4sxyPnqp"
      },
      "source": [
        "# Compilation of model\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-U2u8aeWS5s"
      },
      "source": [
        "*Fitting the model using the augmented train images, ten epochs and validated using the normalized validation set.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MADdetuEDN2H"
      },
      "source": [
        "# Training of model\n",
        "history = model.fit(train_gen, \n",
        "                    epochs=10, \n",
        "                    validation_data=val_gen, \n",
        "                    batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tn5FPt3TWd0a"
      },
      "source": [
        "*This section plots both accuracy and loss during the training.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2eC3EmsQFSz"
      },
      "source": [
        "# Plotting the accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plotting the loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rT89NuJ3Wmzk"
      },
      "source": [
        "*Saving the model. The directory need to be changed to a folder made in your own drive. Run this cell only if you want to save the model.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGotmXiPPuPd"
      },
      "source": [
        "# Save model\n",
        "Save_Dir = \"/content/drive/MyDrive/FLAME_DATASET/Saved_Model\"\n",
        "model.save(Save_Dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBOVP-8wWzu_"
      },
      "source": [
        "*Evaluation of the model using the normalized test set.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpU03eAAPw8Q"
      },
      "source": [
        "# Evaluate model\n",
        "results = model.evaluate(test_gen, \n",
        "                         batch_size=32, \n",
        "                         verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}